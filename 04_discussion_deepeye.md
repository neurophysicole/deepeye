\section{Discussion}

The results supported our hypothesis that the CNN would decode the timeline data with state-of-the-art accuracy. The image data were decoded above chance, but not to the standard set by the state-of-the-art, as hypothesized. The pattern of findings between the exploratory and confirmatory datasets also supported our hypothesis that the results will be reliable and replicated between datasets. To probe<!-- word? --> the resolution of the data, we compared accuracies between the timeline and image datasets and compared relative value of the raw components of the eye movement data (x-coordinates, y-coordinates, pupil size). The timeline dataset was more accurately decoded than the image dataset. When comparing the parcellated datasets, pupil size was the least informative component of the eye movement data. The implications of these findings are discussed further below.

Although several aggregate eye movement features have been tested as task predictors (<!-- REFERENCES -->), to our knowledge no other study has assessed the predictive value of the data format (viz., data in the format of an image). Our results suggest that although CNNs are robust image classifiers, eye movement data is decoded in the standard timeline format more effectively than in image format. This may be a consequence of the inherent resolution of these data formats. Over the span of the trial (six seconds), the eye movements occasionally overlapped. When there was an overlap in the image data format the more recent data points overwrote the older data points. This resulted in some data loss that did not occur when the data was represented in the standard timeline format. Despite the loss of overwritten data, the image format was still classified with better than chance accuracy. To further examine the viability of classifying task from eye movement image datasets, future research might consider decoding 3-dimensional data formats, or more complex color combinations capable of representing overlapping data points. <!-- shorter data timelines may also be an option. May have less differences (less differentiable?) -->

Datasets with lower classification accuracies confused the memorization condition with the search and rate conditions. This suggests that the eye movements associated with the memorization task are likely indicative of underlying cognitive processes that are shared by the search and rate <!-- NOTE: check the rest of the paper to make sure that am consistently referring to this task as 'rate' --> tasks. Previous research (i.e., Krol & Krol <!-- year -->) has attributed the inability to differentiate one condition from the others to a lack of clarity in the data. This attribution is supported in the data by evidence that the parcellated datasets, with fewer defined variables<!-- lower resolution data -->, classified the memorization task less definitively than the other tasks. In cases when the parcellations were decoded as well as the main dataset, the memorize condition was classified as accurately as the other conditions<!-- the last two sentences could probably be clarified... didn't actually run these analyses because pulling out the data is complicated, and this would mean adding A LOT more comparisons -->.

In determining the relative contributions of the the eye movement features used in this study (x-coordinates, y-coordinates, pupil size), pupil size data was consistently the least valuable<!-- wording?.. effective? -->. When pupil size was removed from the exploratory and confirmatory timeline and image datasets classification accuracy remained stable (c.f., non-parcellated dataset). Furthermore, when pupil size data was classified on its own, classification was the lowest of all of the parcellations, and, in one instance, was no better than chance (<!-- which ones were no better than chance, indicate here -->).

The findings from the current study support the notion that black box CNNs are a viable solution to the inverse Yarbus problem. The inconsistent pattern of results for x- and y-coordinate parcellation comparisons are a confirmation of Lukander's (<!-- year -->) assertion that implementing black box solutions to the inverse Yarbus problem can lead to unreliable results. On the other hand, the consistent pattern of results for the non-parcellated timeline and image datasets suggest that black box solutions can be successfully replicated when the resolution of both datasets are equivalent. In reality, the purpose of decoding mental state from eye movement data is often to advance technology to improve educational outcomes <!--(ref)-->, strengthen the independence of physically and mentally handicapped individuals <!--(ref)-->, or improve human human-computer interfaces <!--(ref)-->. To this end, the use of consistently effective and efficient black box solutions can be justified.

Moving forward, variations improvements to the image data may have the potential to advance the current state-of-the-art. If the goal is application, including stimulus feature information may benefit<!-- is this different from exogenously oriented information? is this true Yarbus (as argued in the intro)? --> classification. According to Bulling et al. (<!-- year -->), incorporating stimulus feature information into the dataset may provide diagnostic information in addition to <!--beyond--> spatial<!-- spatiotemporal? --> location. According to Borji & Itti (<!-- year -->), accounting for salient features in the the stimulus might overcome the classifier, leaving little room for the additional consideration of endogenous effects. In this case we know there is the potential for improved classification of the image dataset because the same algorithm consistently classified the timeline data more accurately. Thus<!--word-->, overlying scanpath plot images onto the trial stimulus could potentially improve the performance of the model used in this study.
