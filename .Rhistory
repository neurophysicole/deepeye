themez     <- theme_apa(legend.pos = 'right', legend.font.size = '12') # move legend to top for third version to crop for the legend
zplot       <- plot + lims + plot_labs + bars + error_bars + colors + placement + hz_line + hz_line_lab + bar_labs + themez + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) #no y ticks for the right side of the graph (although now that I am just cropping them, I don't think it really matters...)
zplot
themez     <- theme_apa(legend.pos = 'top', legend.font.size = '12') # move legend to top for third version to crop for the legend
zplot       <- plot + lims + plot_labs + bars + error_bars + colors + placement + hz_line + hz_line_lab + bar_labs + themez + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) #no y ticks for the right side of the graph (although now that I am just cropping them, I don't think it really matters...)
zplot
ages
library('ggplot2')
library('ggpubr')
library('jtools')
# -------------
# supplementary
name = 'Supplementary Analysis'
m.data    <- c(.692, .687, .712, .720, .675, .656) #supplementary means
m.data_str<- c(".692", ".687", ".712", ".720", ".675", ".656") #supplementary means - string version to make them show up how I want them to..
sd.data   <- c(.007, .011, .015, .011, .016, .038) #supplementary sd's
se.data   <- c(.002, .003, .005, .004, .005, .012) #supplementary se's
se_max    <- m.data + se.data #calc y-max
se_min    <- m.data - se.data #calc y-min
parcels   <- c('øMR', 'øMR', 'SøR', 'SøR', 'SMø', 'SMø')
xdataset  <- c('Exploratory', 'Confirmatory', 'Exploratory', 'Confirmatory', 'Exploratory', 'Confirmatory')
parcels   <- factor(parcels, unique(parcels)) #order of bars is order encountered in dataset
xdataset  <- factor(xdataset, unique(xdataset)) #order of bars is order encountered in dataset
plot_data <- data.frame(m.data, sd.data, se.data, se_max, se_min, parcels, xdataset)
chance    <- .5 #chance level
plot        <- ggplot(data = plot_data, mapping = aes(x = parcels, y = m.data, fill = xdataset)) #setup plot
lims        <- coord_cartesian(ylim = c(0.25, .8)) #setting y-axis limit
plot_labs   <- labs(x = name, y = 'Mean Accuracy') #customize axis and legend labels
bars        <- geom_col(data = plot_data, group = xdataset, position = 'dodge') #group bars
error_bars  <- geom_errorbar(aes(ymin = se_min, ymax = se_max), width = 0.1, position = position_dodge(width = 0.9)) #add error bars
colors      <- scale_fill_manual(values = c("lawngreen", "dodgerblue3")) # list of colors --> https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pdf
placement   <- scale_y_continuous(expand = c(0,0), breaks = seq(.25, .75, .05), labels = numform::ff_num(digits = 2, zero = 0)) #put bars on x-, breaks sets the tick marks, numform gets rid of the leading zero on the y-axis
hz_line     <- geom_hline(yintercept = (chance), linetype = 'dashed') #horizontal line indicating chance performance
hz_line_lab <- geom_text(aes(0, chance, label = ' Chance', hjust = 'left', vjust = -.5, fontface = 'plain', family = 'Helvetica')) #Chance line label
bar_labs    <- geom_text(aes(label = m.data_str, vjust = 6, fontface = 'plain', family = 'Helvetica'), position = position_dodge(width = 0.9), size = 4) #add means to the figure
themez     <- theme_apa(legend.pos = 'right', legend.font.size = '12') # move legend to top for third version to crop for the legend
zplot       <- plot + lims + plot_labs + bars + error_bars + colors + placement + hz_line + hz_line_lab + bar_labs + themez# + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) #no y ticks for the right side of the graph (although now that I am just cropping them, I don't think it really matters...)
zplot
# --------
# re-calc
name = 'Primary Analysis Re-Calculated'
m.data    <- c(.689, .666, .725, .755, .652, .673) #re-calc means
m.data_str<- c(".689", ".666", ".725", ".755", ".652", ".673") #re-calc means - string version to make them show up how I want them to..
sd.data   <- c(.034, .076, .011, .045, .018, .041) #re-calc sd's
se.data   <- c(.024, .053, .008, .032, .013, .029) #re-calc se's
se_max    <- m.data + se.data #calc y-max
se_min    <- m.data - se.data #calc y-min
parcels   <- c('øMR', 'øMR', 'SøR', 'SøR', 'SMø', 'SMø')
xdataset  <- c('Exploratory', 'Confirmatory', 'Exploratory', 'Confirmatory', 'Exploratory', 'Confirmatory')
parcels   <- factor(parcels, unique(parcels)) #order of bars is order encountered in dataset
xdataset  <- factor(xdataset, unique(xdataset)) #order of bars is order encountered in dataset
plot_data <- data.frame(m.data, sd.data, se.data, se_max, se_min, parcels, xdataset)
chance    <- .5 #chance level
plot        <- ggplot(data = plot_data, mapping = aes(x = parcels, y = m.data, fill = xdataset)) #setup plot
lims        <- coord_cartesian(ylim = c(0.25, .8)) #setting y-axis limit
plot_labs   <- labs(x = name, y = 'Mean Accuracy') #customize axis and legend labels
bars        <- geom_col(data = plot_data, group = xdataset, position = 'dodge') #group bars
error_bars  <- geom_errorbar(aes(ymin = se_min, ymax = se_max), width = 0.1, position = position_dodge(width = 0.9)) #add error bars
colors      <- scale_fill_manual(values = c("lawngreen", "dodgerblue3")) # list of colors --> https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pdf
placement   <- scale_y_continuous(expand = c(0,0), breaks = seq(.25, .75, .05), labels = numform::ff_num(digits = 2, zero = 0)) #put bars on x-, breaks sets the tick marks, numform gets rid of the leading zero on the y-axis
hz_line     <- geom_hline(yintercept = (chance), linetype = 'dashed') #horizontal line indicating chance performance
hz_line_lab <- geom_text(aes(0, chance, label = '', hjust = 'left', vjust = -.5, fontface = 'plain', family = 'Helvetica')) #Chance line label
bar_labs    <- geom_text(aes(label = m.data_str, vjust = 6, fontface = 'plain', family = 'Helvetica'), position = position_dodge(width = 0.9), size = 4) #add means to the figure
themez     <- theme_apa(legend.pos = 'right', legend.font.size = '12') # move legend to top for third version to crop for the legend
zplot       <- plot + lims + plot_labs + bars + error_bars + colors + placement + hz_line + hz_line_lab + bar_labs + themez# + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) #no y ticks for the right side of the graph (although now that I am just cropping them, I don't think it really matters...)
zplot
themez     <- theme_apa(legend.pos = 'top', legend.font.size = '12') # move legend to top for third version to crop for the legend
zplot       <- plot + lims + plot_labs + bars + error_bars + colors + placement + hz_line + hz_line_lab + bar_labs + themez# + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) #no y ticks for the right side of the graph (although now that I am just cropping them, I don't think it really matters...)
zplot
ckages
library('ggplot2')
library('ggpubr')
library('jtools')
# --------
# IMG!
# img data
m.data    <- c(.436, .449, .449, .430, .413, .400, .439, .466, .414, .392, .412, .422, .333, .340) #means
m.data_str<- c(".436", ".449", ".449", ".430", ".413", ".400", ".439", ".466", ".414", ".392", ".412", ".422", ".333", ".340") #made it into a string so the figure will show it how I want
sd.data   <- c(.020, .012, .014, .044, .014, .026, .014, .012, .017, .030, .016, .024, 5.925e-4, .012) #sd's
se.data   <- c(.006, .004, .004, .014, .004, .008, .005, .004, .005, .009, .005, .008, 1.874e-4, .004) #se's
se_max    <- m.data + se.data #calc y-max
se_min    <- m.data - se.data #calc y-min
paramval  <- c('', '', 'a', '', '', 'a', '', '', 'a', '', '', '', 'a', 'a')
parcels   <- c('XYP', 'XYP', 'øYP', 'øYP', 'XøP', 'XøP', 'XYø', 'XYø', 'øYø', 'øYø', 'Xøø', 'Xøø', 'øøP', 'øøP')
xdataset  <- c('Exploratory', 'Confirmatory', 'Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory')
parcels   <- factor(parcels, unique(parcels)) #order of bars is order encountered in dataset
xdataset  <- factor(xdataset, unique(xdataset)) #order of bars is order encountered in dataset
plot_data <- data.frame(m.data, sd.data, se.data, se_max, se_min, paramval, parcels, xdataset)
chance    <- 1/3 #chance level
plot        <- ggplot(data = plot_data, mapping = aes(x = parcels, y = m.data, fill = xdataset)) #setup plot
lims        <- coord_cartesian(ylim = c(.25, .6)) #setting y-axis limit
plot_labs   <- labs(x = 'Data Subsets', y = 'Mean Accuracy') #customize axis and legend labels
bars        <- geom_col(data = plot_data, group = xdataset, position = 'dodge') #group bars
error_bars  <- geom_errorbar(aes(ymin = se_min, ymax = se_max), width = 0.1, position = position_dodge(width = 0.9)) #add error bars
# colors      <- scale_fill_brewer(palette = 'Set1') #set the color scheme
colors      <- scale_fill_manual(values = c("lawngreen", "dodgerblue3")) # list of colors --> https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pdf
placement   <- scale_y_continuous(expand = c(0,0), breaks = seq(.25, .55, .05), labels = numform::ff_num(digits = 2, zero = 0)) #put bars on x-, breaks sets the tick marks, numform gets rid of the leading zero on the y-axis
hz_line     <- geom_hline(yintercept = (chance), linetype = 'dashed') #horizontal line indicating chance performance
hz_line_lab <- geom_text(aes(0, chance, label = ' Chance', hjust = 'left', vjust = -1, fontface = 'plain', family = 'Helvetica')) #Chance line label
bar_labs    <- geom_text(aes(label = m.data_str, vjust = 4, fontface = 'plain', family = 'Helvetica'), position = position_dodge(width = 0.9), size = 2.5) #add means to the figure
theme       <- theme_apa(legend.pos = 'top', legend.font.size = '12')
zplot      <- plot + lims + plot_labs + bars + error_bars + colors + placement + hz_line + hz_line_lab + bar_labs + theme
zplot
# -------------
# TIMELINE
# timeline data
m.data    <- c(.526, .537, .466, .488, .509, .507, .536, .555, .484, .486, .460, .484, .427, .431) #means
m.data_str<- c(".526", ".537", ".466", ".488", ".509", ".507", ".536", ".555", ".484", ".486", ".460", ".484", ".427", ".431") #made it into a string so the figure will show it how I want
sd.data   <- c(.018, .036, .008, .010, .011, .013, .018, .016, .010, .015, .010, .009, .011, .011) #sd's
se.data   <- c(.006, .011, .002, .003, .003, .004, .006, .005, .003, .005, .003, .003, .003, .004) #se's
se_max    <- m.data + se.data #calc y-max
se_min    <- m.data - se.data #calc y-min
paramval  <- c('', '', '', '', '', '', 'a', '', '', '', '', '', '', '')
# ---------------
# GENERIC TO BOTH
# ---------------
parcels   <- c('XYP', 'XYP', 'øYP', 'øYP', 'XøP', 'XøP', 'XYø', 'XYø', 'øYø', 'øYø', 'Xøø', 'Xøø', 'øøP', 'øøP')
xdataset  <- c('Exploratory', 'Confirmatory', 'Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory','Exploratory', 'Confirmatory')
parcels   <- factor(parcels, unique(parcels)) #order of bars is order encountered in dataset
xdataset  <- factor(xdataset, unique(xdataset)) #order of bars is order encountered in dataset
plot_data <- data.frame(m.data, sd.data, se.data, se_max, se_min, paramval, parcels, xdataset)
chance    <- 1/3 #chance level
plot        <- ggplot(data = plot_data, mapping = aes(x = parcels, y = m.data, fill = xdataset)) #setup plot
lims        <- coord_cartesian(ylim = c(.25, .6)) #setting y-axis limit
plot_labs   <- labs(x = 'Data Subsets', y = 'Mean Accuracy') #customize axis and legend labels
bars        <- geom_col(data = plot_data, group = xdataset, position = 'dodge') #group bars
error_bars  <- geom_errorbar(aes(ymin = se_min, ymax = se_max), width = 0.1, position = position_dodge(width = 0.9)) #add error bars
# colors      <- scale_fill_brewer(palette = 'Set1') #set the color scheme
colors      <- scale_fill_manual(values = c("lawngreen", "dodgerblue3")) # list of colors --> https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pdf
placement   <- scale_y_continuous(expand = c(0,0), breaks = seq(.25, .55, .05), labels = numform::ff_num(digits = 2, zero = 0)) #put bars on x-, breaks sets the tick marks, numform gets rid of the leading zero on the y-axis
hz_line     <- geom_hline(yintercept = (chance), linetype = 'dashed') #horizontal line indicating chance performance
hz_line_lab <- geom_text(aes(0, chance, label = ' Chance', hjust = 'left', vjust = -1, fontface = 'plain', family = 'Helvetica')) #Chance line label
bar_labs    <- geom_text(aes(label = m.data_str, vjust = 4, fontface = 'plain', family = 'Helvetica'), position = position_dodge(width = 0.9), size = 2.5) #add means to the figure
theme       <- theme_apa(legend.pos = 'top', legend.font.size = '12')
zplot      <- plot + lims + plot_labs + bars + error_bars + colors + placement + hz_line + hz_line_lab + bar_labs + theme
zplot
head(df)
head('df')
View(plot)
# ========
# ANALYSIS
# ========
# ---------------
# import packages
library('car')
library('bookdown')
library('ggplot2')
library('ggpubr')
library('jtools')
# ---------
# folder(s)
data_folder = '/Users/zcole/Box/projects/freshprime/dev/freshprime_validity/data/analyze_this'
# ---------
# variables
# df
fname     <- 'clean_allcorr_rt_data_recoded.csv'
datafile  <- paste(data_folder, fname, sep = '/')
df        <- read.csv(file = datafile)
head(df)
# logical indexing - rename vars
options(max.print = 9999) #standard max too low
# conditions
df$condition_clean_allcorr[df$condition_clean_allcorr == 1] = 'Refresh'
df$condition_clean_allcorr[df$condition_clean_allcorr == 2] = 'Nofresh'
df$condition_clean_allcorr[df$condition_clean_allcorr == 3] = 'Novel'
# trial probabilities
df$probability_clean_allcorr[df$probability_clean_allcorr == 1] = 'Predict_Refresh'
df$probability_clean_allcorr[df$probability_clean_allcorr == 2] = 'Predict_Nofresh'
df$probability_clean_allcorr[df$probability_clean_allcorr == 3] = 'Predict_Novel'
df$probability_clean_allcorr[df$probability_clean_allcorr == 4] = 'Predict_Random'
# factors
conds <- factor(df$condition_clean_allcorr) #conditions
probs <- factor(df$probability_clean_allcorr) #probabilities
# -----
# ANOVA
fp_out <- aov(df$probe_rt_clean_allcorr ~ conds + probs + conds*probs, data = df)
# -----------
# assumptions
# homogeneity of variances
plot(fp_out, 1) #plot residuals
leveneTest(fp_out)
# normality
plot(fp_out, 2) #Q-Q plot
fp_residuals <- residuals(object = fp_out) #extract residuals
shapiro.test(x = fp_residuals)
# ------
# report
# redo ANOVA for unequal group numbers
fp_aov <- Anova(fp_out)
# report summary
fp_aov
# post-hoc tests
TukeyHSD(fp_out)
# ------------
# descriptives
# means
ms <- c(
#Refresh
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel']),
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random']),
#Nofresh
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel']),
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random']),
#Novel
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel']),
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random'])
)
# standard deviations
sds <- c(
#Refresh Condition
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel']),
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random']),
#Nofresh Condition
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel']),
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random']),
#Novel Condition
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel']),
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random'])
)
sdx <- sd(df$probe_rt_clean_allcorr)
# standard errors
ses <- c(
#Refresh Condition
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random'])),
#Nofresh Condition
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random'])),
#Novel Condition
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random']))
)
ses <- c(
#Refresh Condition
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random'])),
#Nofresh Condition
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random'])),
#Novel Condition
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random']))
)
# ====
# plot
# ====
# conditions
plot_conds <- length(12)
plot_conds[1:4]   <- 'Refresh'
plot_conds[5:8]   <- 'Nofresh'
plot_conds[9:12]  <- 'Novel'
plot_conds <- factor(plot_conds)
# probabilities
plot_probs <- c('Predict_Refresh', 'Predict_Nofresh', 'Predict_Novel', 'Predict_Random')
plot_probs <- c(plot_probs, plot_probs, plot_probs)
plot_probs <- factor(plot_probs)
# setup data
plot_data <- data.frame(ms, ses, plot_conds, plot_probs)
# reorder the variables
plot_data$plot_conds <- factor(plot_data$plot_conds, levels = c('Refresh', 'Nofresh', 'Novel'))
plot_data$plot_probs <- factor(plot_data$plot_probs, levels = c('Predict_Refresh', 'Predict_Nofresh', 'Predict_Novel', 'Predict_Random'))
plot        <- ggplot(data = plot_data, mapping = aes(x = plot_probs, y = ms, fill = plot_conds))
lims        <- coord_cartesian(ylim = c(.0, .7)) #setting y-axis limit
plot_labs   <- labs(x = 'Condition', y = 'Mean RT') #customize axis and legend labels
bars        <- geom_col(data = plot_data, group = plot_probs, position = 'dodge') #group bars
error_bars  <- geom_errorbar(aes(ymin = ms - (ses), ymax = ms + (ses)), width = 0.1, position = position_dodge(width = 0.9)) #add error bars
colors      <- scale_fill_brewer(palette = 'Paired') #set the color scheme
placement   <- scale_y_continuous(expand = c(0,0)) #put bars on x-axis
theme       <- theme_apa(legend.pos = 'top', legend.font.size = '12')
barplot     <- plot + lims + plot_labs + bars + error_bars + colors + placement + theme
bplot       <- geom_boxplot()
boxplot     <- plot + geom_boxplot(ymin = (ms - sds)/2, ymax = (ms + sds)/2, varwidth = TRUE, notch = TRUE)
boxplot
# ---------------
# import packages
library('car')
library('bookdown')
library('ggplot2')
library('ggpubr')
library('jtools')
# ---------
# folder(s)
data_folder = '/Users/zcole/Box/projects/freshprime/dev/freshprime_validity/data/analyze_this'
# ---------
# variables
# df
fname     <- 'clean_allcorr_rt_data_recoded.csv'
datafile  <- paste(data_folder, fname, sep = '/')
df        <- read.csv(file = datafile)
# ---------
# folder(s)
data_folder = '/Users/zcole/Box/projects/freshprime/dev/freshprime_validity/analysis/clean_data'
# ---------
# variables
# df
fname     <- 'clean_allcorr_rt_data_recoded.csv'
datafile  <- paste(data_folder, fname, sep = '/')
df        <- read.csv(file = datafile)
head(df)
# logical indexing - rename vars
options(max.print = 9999) #standard max too low
# conditions
df$condition_clean_allcorr[df$condition_clean_allcorr == 1] = 'Refresh'
df$condition_clean_allcorr[df$condition_clean_allcorr == 2] = 'Nofresh'
df$condition_clean_allcorr[df$condition_clean_allcorr == 3] = 'Novel'
# trial probabilities
df$probability_clean_allcorr[df$probability_clean_allcorr == 1] = 'Predict_Refresh'
df$probability_clean_allcorr[df$probability_clean_allcorr == 2] = 'Predict_Nofresh'
df$probability_clean_allcorr[df$probability_clean_allcorr == 3] = 'Predict_Novel'
df$probability_clean_allcorr[df$probability_clean_allcorr == 4] = 'Predict_Random'
# factors
conds <- factor(df$condition_clean_allcorr) #conditions
probs <- factor(df$probability_clean_allcorr) #probabilities
# -----
# ANOVA
fp_out <- aov(df$probe_rt_clean_allcorr ~ conds + probs + conds*probs, data = df)
# -----------
# assumptions
# homogeneity of variances
plot(fp_out, 1) #plot residuals
leveneTest(fp_out)
# normality
plot(fp_out, 2) #Q-Q plot
fp_residuals <- residuals(object = fp_out) #extract residuals
shapiro.test(x = fp_residuals)
# ------
# report
# redo ANOVA for unequal group numbers
fp_aov <- Anova(fp_out)
# report summary
fp_aov
# post-hoc tests
TukeyHSD(fp_out)
# ------------
# descriptives
# means
ms <- c(
#Refresh
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel']),
mean(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random']),
#Nofresh
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel']),
mean(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random']),
#Novel
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh']),
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel']),
mean(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random'])
)
# standard deviations
sds <- c(
#Refresh Condition
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel']),
sd(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random']),
#Nofresh Condition
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel']),
sd(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random']),
#Novel Condition
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh']),
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel']),
sd(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random'])
)
sdx <- sd(df$probe_rt_clean_allcorr)
# standard errors
ses <- c(
#Refresh Condition
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random'])),
#Nofresh Condition
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random'])),
#Novel Condition
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$probe_rt_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random']))
)
ses <- c(
#Refresh Condition
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Refresh' & probs == 'Predict_Random'])),
#Nofresh Condition
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Nofresh' & probs == 'Predict_Random'])),
#Novel Condition
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Refresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Nofresh'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Novel'])),
sdx / sqrt(length(df$snum_clean_allcorr[conds == 'Novel' & probs == 'Predict_Random']))
)
# ====
# plot
# ====
# conditions
plot_conds <- length(12)
plot_conds[1:4]   <- 'Refresh'
plot_conds[5:8]   <- 'Nofresh'
plot_conds[9:12]  <- 'Novel'
plot_conds <- factor(plot_conds)
# probabilities
plot_probs <- c('Predict_Refresh', 'Predict_Nofresh', 'Predict_Novel', 'Predict_Random')
plot_probs <- c(plot_probs, plot_probs, plot_probs)
plot_probs <- factor(plot_probs)
# setup data
plot_data <- data.frame(ms, ses, plot_conds, plot_probs)
# reorder the variables
plot_data$plot_conds <- factor(plot_data$plot_conds, levels = c('Refresh', 'Nofresh', 'Novel'))
plot_data$plot_probs <- factor(plot_data$plot_probs, levels = c('Predict_Refresh', 'Predict_Nofresh', 'Predict_Novel', 'Predict_Random'))
plot        <- ggplot(data = plot_data, mapping = aes(x = plot_probs, y = ms, fill = plot_conds))
lims        <- coord_cartesian(ylim = c(.0, .7)) #setting y-axis limit
plot_labs   <- labs(x = 'Condition', y = 'Mean RT') #customize axis and legend labels
bars        <- geom_col(data = plot_data, group = plot_probs, position = 'dodge') #group bars
error_bars  <- geom_errorbar(aes(ymin = ms - (ses), ymax = ms + (ses)), width = 0.1, position = position_dodge(width = 0.9)) #add error bars
colors      <- scale_fill_brewer(palette = 'Paired') #set the color scheme
placement   <- scale_y_continuous(expand = c(0,0)) #put bars on x-axis
theme       <- theme_apa(legend.pos = 'top', legend.font.size = '12')
barplot     <- plot + lims + plot_labs + bars + error_bars + colors + placement + theme
bplot       <- geom_boxplot()
boxplot     <- plot + geom_boxplot(ymin = (ms - sds)/2, ymax = (ms + sds)/2, varwidth = TRUE, notch = TRUE)
boxplot
par(cex = 1.2)
apa_beeplot(
data = df
, id = "snum_clean_allcorr"
, dv = "probe_rt_clean_allcorr"
, factors = c("condition_clean_allcorr", "probability_clean_allcorr")
)
library('papaja')
par(cex = 1.2)
apa_beeplot(
data = df
, id = "snum_clean_allcorr"
, dv = "probe_rt_clean_allcorr"
, factors = c("condition_clean_allcorr", "probability_clean_allcorr")
)
install.packages('beeswarm')
par(cex = 1.2)
apa_beeplot(
data = df
, id = "snum_clean_allcorr"
, dv = "probe_rt_clean_allcorr"
, factors = c("condition_clean_allcorr", "probability_clean_allcorr")
)
barplot
plot_labs   <- labs(x = 'Probability Condition', y = 'Mean RT') #customize axis and legend labels
barplot     <- plot + lims + plot_labs + bars + error_bars + colors + placement + theme
barplot
# post-hoc tests
TukeyHSD(fp_out)
# post-hoc tests
apa_print(TukeyHSD(fp_out))
help(TukeyHSD)
PostHocTest(fp_out)
PostHocTest(fp_out, method = 'hsd')
library('htest')
install.packages('htest')
library('PostHocTest')
install.packages('PostHocTest')
install.packages('DescTools')
install.packages(c("arm", "backports", "bayestestR", "bibtex", "bit", "bit64", "blob", "boot", "broom", "callr", "car", "carData", "checkmate", "citr", "class", "cli", "clipr", "cluster", "coda", "colorspace", "curl", "data.table", "DBI", "dbplyr", "deldir", "deSolve", "devtools", "doParallel", "dplyr", "effectsize", "ellipsis", "elliptic", "emmeans", "fit.models", "foreach", "fs", "ggeffects", "ggplot2", "ggpubr", "ggrepel", "gh", "git2r", "glue", "goftest", "gtable", "gtools", "haven", "Hmisc", "htmlTable", "htmlwidgets", "httr", "insight", "iterators", "jtools", "KernSmooth", "lattice", "lavaan", "lazyeval", "lifecycle", "lubridate", "maptools", "MASS", "Matrix", "matrixStats", "MBESS", "metafor", "mgcv", "modelr", "mvtnorm", "nlme", "nloptr", "nnet", "OpenMx", "openssl", "openxlsx", "parameters", "pbapply", "performance", "pillar", "pkgbuild", "pkgload", "PKI", "plyr", "polyclip", "pracma", "prettyunits", "processx", "profvis", "progress", "ps", "purrr", "quantreg", "R.methodsS3", "R.oo", "R.utils", "rcmdcheck", "RcppArmadillo", "RcppEigen", "RCurl", "remotes", "reshape2", "rJava", "RJSONIO", "robust", "robustbase", "rpart", "rpf", "rrcov", "rsconnect", "RSQLite", "rvest", "sandwich", "scales", "selectr", "sem", "semTools", "shiny", "shinyjs", "sjlabelled", "sp", "SparseM", "spatial", "spatstat", "spatstat.data", "spatstat.utils", "StanHeaders", "survival", "sys", "tibble", "tidyr", "tidyselect", "tidyverse", "TMB", "usethis", "vctrs", "whisker", "withr", "xlsx", "xml2", "zip", "zoo"))
install.packages(c("arm", "backports", "bayestestR", "bibtex", "bit", "bit64", "blob", "boot", "broom", "callr", "car", "carData", "checkmate", "citr", "class", "cli", "clipr", "cluster", "coda", "colorspace", "curl", "data.table", "DBI", "dbplyr", "deldir", "deSolve", "devtools", "doParallel", "dplyr", "effectsize", "ellipsis", "elliptic", "emmeans", "fit.models", "foreach", "fs", "ggeffects", "ggplot2", "ggpubr", "ggrepel", "gh", "git2r", "glue", "goftest", "gtable", "gtools", "haven", "Hmisc", "htmlTable", "htmlwidgets", "httr", "insight", "iterators", "jtools", "KernSmooth", "lattice", "lavaan", "lazyeval", "lifecycle", "lubridate", "maptools", "MASS", "Matrix", "matrixStats", "MBESS", "metafor", "mgcv", "modelr", "mvtnorm", "nlme", "nloptr", "nnet", "OpenMx", "openssl", "openxlsx", "parameters", "pbapply", "performance", "pillar", "pkgbuild", "pkgload", "PKI", "plyr", "polyclip", "pracma", "prettyunits", "processx", "profvis", "progress", "ps", "purrr", "quantreg", "R.methodsS3", "R.oo", "R.utils", "rcmdcheck", "RcppArmadillo", "RcppEigen", "RCurl", "remotes", "reshape2", "rJava", "RJSONIO", "robust", "robustbase", "rpart", "rpf", "rrcov", "rsconnect", "RSQLite", "rvest", "sandwich", "scales", "selectr", "sem", "semTools", "shiny", "shinyjs", "sjlabelled", "sp", "SparseM", "spatial", "spatstat", "spatstat.data", "spatstat.utils", "StanHeaders", "survival", "sys", "tibble", "tidyr", "tidyselect", "tidyverse", "TMB", "usethis", "vctrs", "whisker", "withr", "xlsx", "xml2", "zip", "zoo"))
install.packages(c("arm", "backports", "bayestestR", "bibtex", "bit", "bit64", "blob", "boot", "broom", "callr", "car", "carData", "checkmate", "citr", "class", "cli", "clipr", "cluster", "coda", "colorspace", "curl", "data.table", "DBI", "dbplyr", "deldir", "deSolve", "devtools", "doParallel", "dplyr", "effectsize", "ellipsis", "elliptic", "emmeans", "fit.models", "foreach", "fs", "ggeffects", "ggplot2", "ggpubr", "ggrepel", "gh", "git2r", "glue", "goftest", "gtable", "gtools", "haven", "Hmisc", "htmlTable", "htmlwidgets", "httr", "insight", "iterators", "jtools", "KernSmooth", "lattice", "lavaan", "lazyeval", "lifecycle", "lubridate", "maptools", "MASS", "Matrix", "matrixStats", "MBESS", "metafor", "mgcv", "modelr", "mvtnorm", "nlme", "nloptr", "nnet", "OpenMx", "openssl", "openxlsx", "parameters", "pbapply", "performance", "pillar", "pkgbuild", "pkgload", "PKI", "plyr", "polyclip", "pracma", "prettyunits", "processx", "profvis", "progress", "ps", "purrr", "quantreg", "R.methodsS3", "R.oo", "R.utils", "rcmdcheck", "RcppArmadillo", "RcppEigen", "RCurl", "remotes", "reshape2", "rJava", "RJSONIO", "robust", "robustbase", "rpart", "rpf", "rrcov", "rsconnect", "RSQLite", "rvest", "sandwich", "scales", "selectr", "sem", "semTools", "shiny", "shinyjs", "sjlabelled", "sp", "SparseM", "spatial", "spatstat", "spatstat.data", "spatstat.utils", "StanHeaders", "survival", "sys", "tibble", "tidyr", "tidyselect", "tidyverse", "TMB", "usethis", "vctrs", "whisker", "withr", "xlsx", "xml2", "zip", "zoo"))
install.packages(c("arm", "backports", "bayestestR", "bibtex", "bit", "bit64", "blob", "boot", "broom", "callr", "car", "carData", "checkmate", "citr", "class", "cli", "clipr", "cluster", "coda", "colorspace", "curl", "data.table", "DBI", "dbplyr", "deldir", "deSolve", "devtools", "doParallel", "dplyr", "effectsize", "ellipsis", "elliptic", "emmeans", "fit.models", "foreach", "fs", "ggeffects", "ggplot2", "ggpubr", "ggrepel", "gh", "git2r", "glue", "goftest", "gtable", "gtools", "haven", "Hmisc", "htmlTable", "htmlwidgets", "httr", "insight", "iterators", "jtools", "KernSmooth", "lattice", "lavaan", "lazyeval", "lifecycle", "lubridate", "maptools", "MASS", "Matrix", "matrixStats", "MBESS", "metafor", "mgcv", "modelr", "mvtnorm", "nlme", "nloptr", "nnet", "OpenMx", "openssl", "openxlsx", "parameters", "pbapply", "performance", "pillar", "pkgbuild", "pkgload", "PKI", "plyr", "polyclip", "pracma", "prettyunits", "processx", "profvis", "progress", "ps", "purrr", "quantreg", "R.methodsS3", "R.oo", "R.utils", "rcmdcheck", "RcppArmadillo", "RcppEigen", "RCurl", "remotes", "reshape2", "rJava", "RJSONIO", "robust", "robustbase", "rpart", "rpf", "rrcov", "rsconnect", "RSQLite", "rvest", "sandwich", "scales", "selectr", "sem", "semTools", "shiny", "shinyjs", "sjlabelled", "sp", "SparseM", "spatial", "spatstat", "spatstat.data", "spatstat.utils", "StanHeaders", "survival", "sys", "tibble", "tidyr", "tidyselect", "tidyverse", "TMB", "usethis", "vctrs", "whisker", "withr", "xlsx", "xml2", "zip", "zoo"))
isntall.packages('DescTools')
install.packages('DescTools')
help('emmeans')
library('emmenas')
library('emmeans')
help('emmenas')
help('emmeans')
emmeans(fp_out)
