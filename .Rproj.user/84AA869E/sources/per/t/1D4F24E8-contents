---
title             : "Convolutional neural networks can decode eye movement data: A black box approach to predicting task from eye movements"
shorttitle        : "Deep learning and eye tracking"

author: 
  - name          : "Zachary J. Cole"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "238 Burnett Hall, Lincoln, NE 68588-0308"
    
    email         : "z@neurophysicole.com"
  - name          : "Karl M. Kuntzelman"
    affiliation   : "1"
  - name          : "Michael D. Dodd"
    affiliation   : "1"
  - name          : "Matthew R. Johnson"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Nebraska-Lincoln"
    
authornote        : >
  The data used for the exploratory and confirmatory analyses in the present manuscript are derived from experiments funded by NIH/NEI Grant 1R01EY022974 to MDD. Additionally, work done to develop the analysis approach was supported by NSF/EPSCoR grant #1632849 and NIH grant GM130461 awarded to MRJ and colleagues.

abstract          : >
  Previous attempts to classify task from eye movement data relied on model architectures designed to emulate theoretically defined cognitive processes, and/or data that has been processed into aggregate (e.g., fixations, saccades) or statistical (e.g., fixation density) features. _Black box_ convolutional neural networks (CNNs) are capable of identifying relevant features in raw and minimally processed data and images, but difficulty interpreting the mechanisms underlying these model architectures have contributed to challenges in generalizing lab-trained CNNs to applied contexts. In the current study, a CNN classifier was used to classify task from two eye movement datasets (Exploratory and Confirmatory) in which participants searched, memorized, or rated indoor and outdoor scene images. The Exploratory dataset was used to tune the hyperparameters of the model, and the resulting model architecture was re-trained, validated, and tested on the Confirmatory dataset. The data were formatted into raw timeline data (i.e., x-coordinate, y-coordinate, pupil size) and minimally processed images. To further understand the relative informational value of the raw components of the eye movement data, the timeline and image datasets were broken down into subsets with one or more of the components of the data systematically removed. Average classification accuracies were compared between datasets and subsets. Classification of the timeline data consistently outperformed the image data. The Memorize condition was most often confused with the Search and Rate conditions. Pupil size was the least uniquely informative eye movement component when compared with the x- and y-coordinates. The general pattern of results for the Exploratory dataset was replicated in the Confirmatory dataset. Overall, the present study provides a practical and reliable black box solution to the inverse Yarbus problem.
#should be 200 words (approximately)

keywords          : "deep learning, eye tracking, convolutional neural network, cognitive state, endogenous attention"
wordcount         : "7260" #6305 (intro: 1965, methods: 1532, results: 1261, discussion: 1400, appendix: 460, references: 642

bibliography      : ["references/blackbox_manuscript.bib"]

figsintext        : yes
floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

mainfont          : Helvetica

header-includes:
   - \usepackage{multirow}
   - \usepackage{graphicx}
   - \usepackage{array}
   - \usepackage{setspace}
   - \captionsetup[figure]{font={stretch=1,scriptsize}}
  
appendix          : "supp_analysis.Rmd"

documentclass     : "apa6"
classoption       : "man" #doc
output            : papaja::apa6_pdf #apa_docx
fig_caption       : yes
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

<!-- Intro -->
```{r child = "01_intro_deepeye.md"}
```

<!-- Methods -->
```{r child = "02_methods_deepeye.md"}
```

<!-- Results -->
```{r child = "03_results_deepeye.md"}
```

<!-- Discussion -->
```{r child = "04_discussion_deepeye.md"}
```

\newpage
<!-- References -->
# References
```{r create_r-references}
r_refs(file = "references/blackbox_manuscript_r.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
